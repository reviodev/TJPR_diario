FROM python:3.10-slim

WORKDIR /app

# Instalar Chrome e pacotes necess√°rios + cron
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    unzip \
    cron \
    && wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add - \
    && echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list \
    && apt-get update \
    && apt-get install -y google-chrome-stable \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copiar o c√≥digo e arquivos de configura√ß√£o
COPY scraper.py .
COPY .env* .

# Criar diret√≥rio para logs e downloads
RUN mkdir -p /app/Diarios /app/logs

# Configurar tarefa cron para executar o scraper todos os dias √†s 10:00
RUN echo "0 10 * * * cd /app && python /app/scraper.py >> /app/logs/scraper_\$(date +\%Y\%m\%d).log 2>&1" > /etc/cron.d/scraper-cron
RUN chmod 0644 /etc/cron.d/scraper-cron
RUN crontab /etc/cron.d/scraper-cron

# Criar script de inicializa√ß√£o
COPY <<'EOT' /app/entrypoint.sh
#!/bin/bash
echo "üîÑ TJPR Scraper service started"
echo "üìÖ Cron job scheduled to run at 10:00 AM daily"
service cron start
echo "‚úÖ Cron service started"
echo "üìä Logs will be available at /app/logs/"

# Executar uma vez na inicializa√ß√£o (opcional)
python /app/scraper.py >> /app/logs/scraper_initial.log 2>&1

# Manter o container em execu√ß√£o
tail -f /dev/null
EOT

RUN chmod +x /app/entrypoint.sh

# Usa o script de inicializa√ß√£o em vez de executar diretamente o scraper
CMD ["/app/entrypoint.sh"]